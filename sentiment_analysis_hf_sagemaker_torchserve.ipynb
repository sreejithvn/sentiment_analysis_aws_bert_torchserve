{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f8373d",
   "metadata": {},
   "source": [
    "# Sentiment analysis on product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fbf2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b2955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'hugging-face/sentiment-analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ddbf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"arn:aws:iam::XXXXXXXXXX:role/Sagemaker-FullAccess\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cf7e4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f914f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(role=role,\n",
    "                                     framework_version='0.23-1',\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2f56ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2023-03-18-15-21-18-761\n",
      "Inputs:  [{'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/input/code/preprocessing_hf.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'training', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/training', 'LocalPath': '/opt/ml/processing/output/training', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/validation', 'LocalPath': '/opt/ml/processing/output/validation', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............................\u001b[34mCollecting transformers==4.6.1\n",
      "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 72.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.10.0-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 880.6/880.6 kB 61.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /miniconda3/lib/python3.7/site-packages (from transformers==4.6.1) (6.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /miniconda3/lib/python3.7/site-packages (from transformers==4.6.1) (1.19.2)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 757.1/757.1 kB 60.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 15.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting packaging\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.7/42.7 kB 8.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 92.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /miniconda3/lib/python3.7/site-packages (from transformers==4.6.1) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.1) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.1) (3.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.7/site-packages (from requests->transformers==4.6.1) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /miniconda3/lib/python3.7/site-packages (from requests->transformers==4.6.1) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.7/site-packages (from requests->transformers==4.6.1) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.7/site-packages (from requests->transformers==4.6.1) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.7/site-packages (from sacremoses->transformers==4.6.1) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /miniconda3/lib/python3.7/site-packages (from sacremoses->transformers==4.6.1) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /miniconda3/lib/python3.7/site-packages (from sacremoses->transformers==4.6.1) (1.2.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=70d6710a7605167e046479ea3233b7e4872b5e46a6146973f2cf72d08d4e877b\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\u001b[0m\n",
      "\u001b[34mSuccessfully built sacremoses\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, tqdm, regex, packaging, filelock, huggingface-hub, sacremoses, transformers\u001b[0m\n",
      "\u001b[34mSuccessfully installed filelock-3.10.0 huggingface-hub-0.0.8 packaging-23.0 regex-2022.10.31 sacremoses-0.0.53 tokenizers-0.10.3 tqdm-4.65.0 transformers-4.6.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mCollecting datasets==1.6.2\u001b[0m\n",
      "\u001b[34m  Downloading datasets-1.6.2-py3-none-any.whl (221 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 221.8/221.8 kB 20.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /miniconda3/lib/python3.7/site-packages (from datasets==1.6.2) (23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /miniconda3/lib/python3.7/site-packages (from datasets==1.6.2) (2.28.1)\u001b[0m\n",
      "\u001b[34mCollecting tqdm<4.50.0,>=4.27\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.8/69.8 kB 12.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.7/115.7 kB 17.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<0.1.0 in /miniconda3/lib/python3.7/site-packages (from datasets==1.6.2) (0.0.8)\u001b[0m\n",
      "\u001b[34mCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 213.1/213.1 kB 36.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=1.0.0<4.0.0 in /miniconda3/lib/python3.7/site-packages (from datasets==1.6.2) (1.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /miniconda3/lib/python3.7/site-packages (from datasets==1.6.2) (6.0.0)\u001b[0m\n",
      "\u001b[34mCollecting dill\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 19.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.7/site-packages (from datasets==1.6.2) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting fsspec\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.0/143.0 kB 23.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /miniconda3/lib/python3.7/site-packages (from datasets==1.6.2) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /miniconda3/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets==1.6.2) (3.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /miniconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.6.2) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.6.2) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.6.2) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.6.2) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->datasets==1.6.2) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->datasets==1.6.2) (3.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas->datasets==1.6.2) (2022.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.7/site-packages (from pandas->datasets==1.6.2) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.6.2) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xxhash, tqdm, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed datasets-1.6.2 dill-0.3.6 fsspec-2023.1.0 multiprocess-0.70.14 tqdm-4.49.0 xxhash-3.2.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\u001b[0m\n",
      "\u001b[34mReceived Arguments Namespace(s3_bucket='sagemaker-us-east-1-312202024311', s3_prefix='hugging-face/sentiment-analysis', threshold=4)\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.43k [00:00<?, ?B/s]#015Downloading: 4.36kB [00:00, 3.30MB/s]                   \u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.03k [00:00<?, ?B/s]#015Downloading: 2.40kB [00:00, 1.26MB/s]                   \u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset generated_reviews_enth/generated_reviews_enth (download: 56.73 MiB, generated: 173.78 MiB, post-processed: Unknown size, total: 230.51 MiB) to /root/.cache/huggingface/datasets/generated_reviews_enth/generated_reviews_enth/1.0.0/48de9722233d125bf2408e04a2efe5281d2de21331da10b4237750dd77ee3a04...\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/59.5M [00:00<?, ?B/s]#015Downloading:  13%|█▎        | 7.47M/59.5M [00:00<00:00, 74.7MB/s]#015Downloading:  26%|██▌       | 15.4M/59.5M [00:00<00:00, 75.9MB/s]#015Downloading:  39%|███▉      | 23.2M/59.5M [00:00<00:00, 76.8MB/s]#015Downloading:  52%|█████▏    | 31.2M/59.5M [00:00<00:00, 77.6MB/s]#015Downloading:  66%|██████▌   | 39.1M/59.5M [00:00<00:00, 78.0MB/s]#015Downloading:  79%|███████▉  | 47.1M/59.5M [00:00<00:00, 78.7MB/s]#015Downloading:  92%|█████████▏| 54.8M/59.5M [00:00<00:00, 78.1MB/s]#015Downloading: 100%|██████████| 59.5M/59.5M [00:00<00:00, 78.3MB/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mDataset generated_reviews_enth downloaded and prepared to /root/.cache/huggingface/datasets/generated_reviews_enth/generated_reviews_enth/1.0.0/48de9722233d125bf2408e04a2efe5281d2de21331da10b4237750dd77ee3a04. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34mtrain dataset shape: (141369, 3)\u001b[0m\n",
      "\u001b[34mvalidation dataset shape: (15708, 3)\u001b[0m\n",
      "\u001b[34m#0150 examples [00:00, ? examples/s]#0152962 examples [00:00, 29612.19 examples/s]#0155937 examples [00:00, 29651.19 examples/s]#0158903 examples [00:00, 29653.65 examples/s]#01510853 examples [00:00, 24292.96 examples/s]#01513895 examples [00:00, 25854.10 examples/s]#01516878 examples [00:00, 26930.76 examples/s]#01519879 examples [00:00, 27784.67 examples/s]#01522497 examples [00:00, 25581.21 examples/s]#01524977 examples [00:00, 23627.52 examples/s]#01527949 examples [00:01, 25173.54 examples/s]#01530477 examples [00:01, 23983.63 examples/s]#01533565 examples [00:01, 25703.67 examples/s]#01536570 examples [00:01, 26869.32 examples/s]#01539539 examples [00:01, 27655.35 examples/s]#01542344 examples [00:01, 25859.43 examples/s]#01545378 examples [00:01, 27057.92 examples/s]#01548382 examples [00:01, 27886.49 examples/s]#01551213 examples [00:01, 25356.17 examples/s]#01554320 examples [00:02, 26836.53 examples/s]#01557308 examples [00:02, 27681.42 examples/s]#01560136 examples [00:02, 25105.86 examples/s]#01563239 examples [00:02, 26629.74 examples/s]#01566220 examples [00:02, 27507.14 examples/s]#01569175 examples [00:02, 28089.51 examples/s]#01572035 examples [00:02, 23618.71 examples/s]#01574985 examples [00:02, 25120.26 examples/s]#01577929 examples [00:02, 26276.33 examples/s]#01580666 examples [00:03, 24777.01 examples/s]#01583739 examples [00:03, 26304.17 examples/s]#01586709 examples [00:03, 27235.51 examples/s]#01589597 examples [00:03, 27707.39 examples/s]#01592421 examples [00:03, 25530.61 examples/s]#01595479 examples [00:03, 26859.53 examples/s]#01598425 examples [00:03, 27589.20 examples/s]#015101237 examples [00:03, 25670.79 examples/s]#015104180 examples [00:03, 26693.55 examples/s]#015107152 examples [00:04, 27533.66 examples/s]#015110000 examples [00:04, 24917.30 examples/s]#015113051 examples [00:04, 26365.98 examples/s]#015116087 examples [00:04, 27447.95 examples/s]#015118898 examples [00:04, 25042.37 examples/s]#015121490 examples [00:04, 23889.20 examples/s]#015124584 examples [00:04, 25641.96 examples/s]#015127619 examples [00:04, 26892.55 examples/s]#015130386 examples [00:04, 25081.90 examples/s]#015133456 examples [00:05, 26538.73 examples/s]#015136529 examples [00:05, 27668.06 examples/s]#015139496 examples [00:05, 28239.47 examples/s]#015                                            #015#0150 examples [00:00, ? examples/s]#0153019 examples [00:00, 30180.75 examples/s]#0156079 examples [00:00, 30305.23 examples/s]#0159074 examples [00:00, 30196.70 examples/s]#01511059 examples [00:00, 25986.78 examples/s]#01514060 examples [00:00, 27074.20 examples/s]#015                                           #015#0150 examples [00:00, ? examples/s]#0153035 examples [00:00, 30348.51 examples/s]#0156137 examples [00:00, 30546.76 examples/s]#0157925 examples [00:00, 25188.97 examples/s]#01510000 examples [00:00, 22659.58 examples/s]#01513060 examples [00:00, 24569.89 examples/s]#01516124 examples [00:00, 26121.89 examples/s]#015                                           #015Parameter 'function'=<function map_review_stars_to_sentiment at 0x7f7244260d40> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/141369 [00:00<?, ?ex/s]#015  1%|          | 1457/141369 [00:00<00:09, 14567.51ex/s]#015  2%|▏         | 2867/141369 [00:00<00:09, 14422.76ex/s]#015  3%|▎         | 4240/141369 [00:00<00:09, 14205.12ex/s]#015  4%|▍         | 5702/141369 [00:00<00:09, 14324.57ex/s]#015  5%|▌         | 7111/141369 [00:00<00:09, 14250.61ex/s]#015  6%|▌         | 8571/141369 [00:00<00:09, 14353.29ex/s]#015  7%|▋         | 9911/141369 [00:00<00:09, 14051.34ex/s]#015  8%|▊         | 11318/141369 [00:00<00:09, 14056.05ex/s]#015  9%|▉         | 12781/141369 [00:00<00:09, 14221.90ex/s]#015 10%|█         | 14179/141369 [00:01<00:08, 14146.43ex/s]#015 11%|█         | 15644/141369 [00:01<00:08, 14293.59ex/s]#015 12%|█▏        | 17046/141369 [00:01<00:08, 14085.00ex/s]#015 13%|█▎        | 18511/141369 [00:01<00:08, 14247.60ex/s]#015 14%|█▍        | 19924/141369 [00:01<00:08, 14061.50ex/s]#015 15%|█▌        | 21329/141369 [00:01<00:08, 14056.90ex/s]#015 16%|█▌        | 22801/141369 [00:01<00:08, 14248.50ex/s]#015 17%|█▋        | 24223/141369 [00:01<00:08, 14193.39ex/s]#015 18%|█▊        | 25679/141369 [00:01<00:08, 14301.39ex/s]#015 19%|█▉        | 27108/141369 [00:01<00:08, 14194.61ex/s]#015 20%|██        | 28527/141369 [00:02<00:07, 14150.06ex/s]#015 21%|██        | 29942/141369 [00:02<00:08, 13871.81ex/s]#015 22%|██▏       | 31331/141369 [00:02<00:07, 13756.74ex/s]#015 23%|██▎       | 32795/141369 [00:02<00:07, 14009.98ex/s]#015 24%|██▍       | 34198/141369 [00:02<00:08, 13058.39ex/s]#015 25%|██▌       | 35667/141369 [00:02<00:07, 13508.02ex/s]#015 26%|██▌       | 37071/141369 [00:02<00:07, 13662.60ex/s]#015 27%|██▋       | 38453/141369 [00:02<00:07, 13709.07ex/s]#015 28%|██▊       | 39832/141369 [00:02<00:07, 13558.26ex/s]#015 29%|██▉       | 41223/141369 [00:02<00:07, 13659.71ex/s]#015 30%|███       | 42694/141369 [00:03<00:07, 13956.20ex/s]#015 31%|███       | 44098/141369 [00:03<00:06, 13979.32ex/s]#015 32%|███▏      | 45531/141369 [00:03<00:06, 14082.25ex/s]#015 33%|███▎      | 46996/141369 [00:03<00:06, 14245.93ex/s]#015 34%|███▍      | 48423/141369 [00:03<00:06, 13804.42ex/s]#015 35%|███▌      | 49808/141369 [00:03<00:06, 13609.84ex/s]#015 36%|███▌      | 51191/141369 [00:03<00:06, 13674.29ex/s]#015 37%|███▋      | 52655/141369 [00:03<00:06, 13949.53ex/s]#015 38%|███▊      | 54061/141369 [00:03<00:06, 13981.59ex/s]#015 39%|███▉      | 55526/141369 [00:03<00:06, 14173.84ex/s]#015 40%|████      | 56948/141369 [00:04<00:05, 14187.37ex/s]#015 41%|████▏     | 58369/141369 [00:04<00:06, 13731.06ex/s]#015 42%|████▏     | 59747/141369 [00:04<00:06, 13475.53ex/s]#015 43%|████▎     | 61117/141369 [00:04<00:05, 13540.36ex/s]#015 44%|████▍     | 62584/141369 [00:04<00:05, 13858.28ex/s]#015 45%|████▌     | 64000/141369 [00:04<00:05, 13897.96ex/s]#015 46%|████▋     | 65459/141369 [00:04<00:05, 14097.46ex/s]#015 47%|████▋     | 66872/141369 [00:04<00:05, 13966.97ex/s]#015 48%|████▊     | 68271/141369 [00:04<00:05, 13578.78ex/s]#015 49%|████▉     | 69633/141369 [00:05<00:05, 13470.66ex/s]#015 50%|█████     | 71000/141369 [00:05<00:05, 13526.02ex/s]#015 51%|█████▏    | 72459/141369 [00:05<00:04, 13828.48ex/s]#015 52%|█████▏    | 73906/141369 [00:05<00:04, 14014.62ex/s]#015 53%|█████▎    | 75311/141369 [00:05<00:04, 13947.21ex/s]#015 54%|█████▍    | 76708/141369 [00:05<00:04, 13719.48ex/s]#015 55%|█████▌    | 78083/141369 [00:05<00:04, 13387.03ex/s]#015 56%|█████▌    | 79426/141369 [00:05<00:04, 13335.41ex/s]#015 57%|█████▋    | 80824/141369 [00:05<00:04, 13520.82ex/s]#015 58%|█████▊    | 82245/141369 [00:05<00:04, 13718.86ex/s]#015 59%|█████▉    | 83715/141369 [00:06<00:04, 13997.87ex/s]#015 60%|██████    | 85118/141369 [00:06<00:04, 13919.59ex/s]#015 61%|██████    | 86513/141369 [00:06<00:04, 13608.79ex/s]#015 62%|██████▏   | 87877/141369 [00:06<00:03, 13503.13ex/s]#015 63%|██████▎   | 89230/141369 [00:06<00:03, 13221.39ex/s]#015 64%|██████▍   | 90595/141369 [00:06<00:03, 13345.80ex/s]#015 65%|██████▌   | 92004/141369 [00:06<00:03, 13559.84ex/s]#015 66%|██████▌   | 93483/141369 [00:06<00:03, 13904.52ex/s]#015 67%|██████▋   | 94878/141369 [00:06<00:03, 13843.38ex/s]#015 68%|██████▊   | 96266/141369 [00:06<00:03, 13507.49ex/s]#015 69%|██████▉   | 97621/141369 [00:07<00:03, 12333.10ex/s]#015 70%|██████▉   | 98945/141369 [00:07<00:03, 12589.42ex/s]#015 71%|███████   | 100221/141369 [00:07<00:03, 12601.93ex/s]#015 72%|███████▏  | 101686/141369 [00:07<00:03, 13152.77ex/s]#015 73%|███████▎  | 103084/141369 [00:07<00:02, 13387.68ex/s]#015 74%|███████▍  | 104462/141369 [00:07<00:02, 13502.09ex/s]#015 75%|███████▍  | 105821/141369 [00:07<00:02, 13419.57ex/s]#015 76%|███████▌  | 107169/141369 [00:07<00:02, 13223.18ex/s]#015 77%|███████▋  | 108498/141369 [00:07<00:02, 13240.57ex/s]#015 78%|███████▊  | 109832/141369 [00:07<00:02, 13267.94ex/s]#015 79%|███████▊  | 111216/141369 [00:08<00:02, 13432.80ex/s]#015 80%|███████▉  | 112687/141369 [00:08<00:02, 13790.83ex/s]#015 81%|████████  | 114070/141369 [00:08<00:02, 13457.02ex/s]#015 82%|████████▏ | 115421/141369 [00:08<00:01, 13395.50ex/s]#015 83%|████████▎ | 116764/141369 [00:08<00:01, 13318.69ex/s]#015 84%|████████▎ | 118099/141369 [00:08<00:01, 13157.93ex/s]#015 84%|████████▍ | 119417/141369 [00:08<00:01, 13154.31ex/s]#015 85%|████████▌ | 120824/141369 [00:08<00:01, 13414.82ex/s]#015 86%|████████▋ | 122220/141369 [00:08<00:01, 13573.20ex/s]#015 87%|████████▋ | 123582/141369 [00:09<00:01, 13587.13ex/s]#015 88%|████████▊ | 124943/141369 [00:09<00:01, 13474.34ex/s]#015 89%|████████▉ | 126292/141369 [00:09<00:01, 13265.40ex/s]#015 90%|█████████ | 127621/141369 [00:09<00:01, 13129.80ex/s]#015 91%|█████████ | 128936/141369 [00:09<00:01, 10169.64ex/s]#015 92%|█████████▏| 130218/141369 [00:09<00:01, 10840.80ex/s]#015 93%|█████████▎| 131688/141369 [00:09<00:00, 11767.39ex/s]#015 94%|█████████▍| 133000/141369 [00:09<00:00, 12094.57ex/s]#015 95%|█████████▌| 134326/141369 [00:09<00:00, 12419.98ex/s]#015 96%|█████████▌| 135637/141369 [00:10<00:00, 12618.84ex/s]#015 97%|█████████▋| 136954/141369 [00:10<00:00, 12778.94ex/s]#015 98%|█████████▊| 138255/141369 [00:10<00:00, 12744.89ex/s]#015 99%|█████████▊| 139546/141369 [00:10<00:00, 12772.27ex/s]#015100%|█████████▉| 140963/141369 [00:10<00:00, 13161.63ex/s]#015100%|██████████| 141369/141369 [00:10<00:00, 13522.53ex/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/15708 [00:00<?, ?ex/s]#015  9%|▉         | 1448/15708 [00:00<00:00, 14476.70ex/s]#015 18%|█▊        | 2905/15708 [00:00<00:00, 14502.86ex/s]#015 27%|██▋       | 4318/15708 [00:00<00:00, 14387.08ex/s]#015 37%|███▋      | 5778/15708 [00:00<00:00, 14449.66ex/s]#015 46%|████▌     | 7195/15708 [00:00<00:00, 14363.57ex/s]#015 55%|█████▍    | 8562/15708 [00:00<00:00, 14146.23ex/s]#015 63%|██████▎   | 9886/15708 [00:00<00:00, 13860.95ex/s]#015 72%|███████▏  | 11298/15708 [00:00<00:00, 13935.68ex/s]#015 81%|████████  | 12724/15708 [00:00<00:00, 14029.67ex/s]#015 90%|█████████ | 14143/15708 [00:01<00:00, 14077.04ex/s]#015 99%|█████████▉| 15621/15708 [00:01<00:00, 14278.55ex/s]#015100%|██████████| 15708/15708 [00:01<00:00, 14197.20ex/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 483/483 [00:00<00:00, 335kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 45.3MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 466k/466k [00:00<00:00, 29.9MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 23.9kB/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:36<00:00, 36.84s/ba]#015100%|██████████| 1/1 [00:36<00:00, 36.84s/ba]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:03<00:00,  3.07s/ba]#015100%|██████████| 1/1 [00:03<00:00,  3.07s/ba]\u001b[0m\n",
      "\n",
      "CPU times: user 2.46 s, sys: 270 ms, total: 2.73 s\n",
      "Wall time: 6min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code='preprocessing_hf.py',\n",
    "                      outputs=[ProcessingOutput(source='/opt/ml/processing/output/training',\n",
    "                                                output_name='training'),\n",
    "                               ProcessingOutput(source='/opt/ml/processing/output/validation',\n",
    "                                                output_name='validation')],\n",
    "                      arguments=[\"--threshold\", \"4\",\n",
    "                                 \"--s3-bucket\", bucket,\n",
    "                                 \"--s3-prefix\", prefix]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4684fb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'code',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/input/code/preprocessing_hf.py',\n",
       "    'LocalPath': '/opt/ml/processing/input/code',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'training',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/training',\n",
       "     'LocalPath': '/opt/ml/processing/output/training',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False},\n",
       "   {'OutputName': 'validation',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/validation',\n",
       "     'LocalPath': '/opt/ml/processing/output/validation',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False}]},\n",
       " 'ProcessingJobName': 'sagemaker-scikit-learn-2023-03-18-15-21-18-761',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
       "   'InstanceType': 'ml.m5.xlarge',\n",
       "   'VolumeSizeInGB': 30}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "  'ContainerEntrypoint': ['python3',\n",
       "   '/opt/ml/processing/input/code/preprocessing_hf.py'],\n",
       "  'ContainerArguments': ['--threshold',\n",
       "   '4',\n",
       "   '--s3-bucket',\n",
       "   'sagemaker-us-east-1-312202024311',\n",
       "   '--s3-prefix',\n",
       "   'hugging-face/sentiment-analysis']},\n",
       " 'RoleArn': 'arn:aws:iam::312202024311:role/Sagemaker-FullAccess',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:312202024311:processing-job/sagemaker-scikit-learn-2023-03-18-15-21-18-761',\n",
       " 'ProcessingJobStatus': 'Completed',\n",
       " 'ProcessingEndTime': datetime.datetime(2023, 3, 18, 15, 27, 36, 465000, tzinfo=tzlocal()),\n",
       " 'ProcessingStartTime': datetime.datetime(2023, 3, 18, 15, 26, 8, 391000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 3, 18, 15, 27, 36, 787000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2023, 3, 18, 15, 21, 20, 941000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '10409cce-8e2c-4f48-b89e-db11957c8d2c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '10409cce-8e2c-4f48-b89e-db11957c8d2c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1828',\n",
       "   'date': 'Sat, 18 Mar 2023 18:19:06 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c1fcfde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/training\n",
      "s3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/validation\n"
     ]
    }
   ],
   "source": [
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    print(output['S3Output']['S3Uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e118f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n",
      "sagemaker-scikit-learn-2023-03-18-15-21-18-761\n",
      "{'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30}}\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing_job_description['ProcessingJobStatus'])\n",
    "print(preprocessing_job_description['ProcessingJobName'])\n",
    "print(preprocessing_job_description['ProcessingResources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc49d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"s3://sagemaker-us-east-1-XXXXXXXXXXX/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/training\"\n",
    "valid_data_path = \"s3://sagemaker-us-east-1-XXXXXXXXXXX/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9792e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_prefix = 'hugging-face/sentiment-analysis'\n",
    "# train_data_path = session.upload_data(path='./training/', bucket=bucket, key_prefix=s3_prefix+'/training')\n",
    "# valid_data_path = session.upload_data(path='./validation/', bucket=bucket, key_prefix=s3_prefix+'/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9dc71",
   "metadata": {},
   "source": [
    "# Fine-tuning & starting Sagemaker Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d359c94",
   "metadata": {},
   "source": [
    "## Fine-tune the Hugging Face model on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01e9da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'epochs': 1,\n",
    "    'train_batch_size': 32,\n",
    "    'model_name':'distilbert-base-uncased'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a62078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    role=role,\n",
    "    # Fine-tuning script\n",
    "    entry_point='train_hf.py',\n",
    "    hyperparameters=hyperparameters,\n",
    "    # Infrastructure\n",
    "    transformers_version='4.6.1',\n",
    "    pytorch_version='1.7.1',\n",
    "    py_version='py36',\n",
    "#     checkpoint_s3_uri=f's3://{bucket}/{prefix}/checkpoints',\n",
    "#     use_spot_instances=True,\n",
    "#     # max_wait should be equal to or greater than max_run in seconds\n",
    "#     max_wait=3600,\n",
    "#     max_run=3000,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ece7c227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 17:09:52 Starting - Starting the training job...ProfilerReport-1679159391: InProgress\n",
      "...\n",
      "2023-03-18 17:10:56 Starting - Preparing the instances for training...\n",
      "2023-03-18 17:11:23 Downloading - Downloading input data...\n",
      "2023-03-18 17:11:58 Training - Downloading the training image..\n",
      "2023-03-18 17:27:40 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-03-18 17:14:26,567 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-03-18 17:14:26,598 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-03-18 17:14:26,601 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-03-18 17:14:26,860 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"valid\": \"/opt/ml/input/data/valid\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"train_batch_size\": 32\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2023-03-18-17-09-49-922\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-312202024311/huggingface-pytorch-training-2023-03-18-17-09-49-922/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_hf\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_hf.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_hf.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"valid\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_hf\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-312202024311/huggingface-pytorch-training-2023-03-18-17-09-49-922/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"valid\":\"/opt/ml/input/data/valid\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2023-03-18-17-09-49-922\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-312202024311/huggingface-pytorch-training-2023-03-18-17-09-49-922/source/sourcedir.tar.gz\",\"module_name\":\"train_hf\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_hf.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALID=/opt/ml/input/data/valid\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_hf.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\u001b[0m\n",
      "\u001b[34mtrain data directory: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mvalidation data directory: /opt/ml/input/data/valid\u001b[0m\n",
      "\u001b[34mmodel name: distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.709 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.786 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.787 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.788 algo-1:27 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.789 algo-1:27 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.789 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.920 algo-1:27 INFO hook.py:591] name:distilbert.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.921 algo-1:27 INFO hook.py:591] name:distilbert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.921 algo-1:27 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.921 algo-1:27 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.921 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.921 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.921 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.921 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.922 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.922 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.922 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.922 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.922 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.922 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.923 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.923 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.923 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.923 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.923 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.923 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.923 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.924 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.924 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.924 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.924 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.924 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.924 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.924 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.925 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.925 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.925 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.925 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.925 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.925 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.925 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.926 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.926 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.926 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.926 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.926 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.926 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.927 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.927 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.927 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.927 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.927 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.927 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.928 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.929 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.929 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.929 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.929 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.929 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.929 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.930 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.930 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.930 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.930 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.930 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.930 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.930 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.931 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.932 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.933 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.934 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.934 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.934 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.934 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.934 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.934 algo-1:27 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.935 algo-1:27 INFO hook.py:591] name:pre_classifier.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.935 algo-1:27 INFO hook.py:591] name:pre_classifier.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.935 algo-1:27 INFO hook.py:591] name:classifier.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.935 algo-1:27 INFO hook.py:591] name:classifier.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.935 algo-1:27 INFO hook.py:593] Total Trainable Params: 66955010\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.935 algo-1:27 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-03-18 17:14:36.938 algo-1:27 INFO hook.py:488] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34m{'loss': 0.3025, 'learning_rate': 4.434133091896786e-05, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2597, 'learning_rate': 3.868266183793572e-05, 'epoch': 0.23}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'loss': 0.244, 'learning_rate': 3.302399275690358e-05, 'epoch': 0.34}\u001b[0m\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InvalidSignatureException) when calling the DescribeLogStreams operation: Signature expired: 20230318T173231Z is now earlier than 20230318T174337Z (20230318T174837Z - 5 min.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhuggingface_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/conda_sagemaker/lib/python3.10/site-packages/sagemaker/estimator.py:953\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 953\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/conda_sagemaker/lib/python3.10/site-packages/sagemaker/estimator.py:1940\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1940\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/conda_sagemaker/lib/python3.10/site-packages/sagemaker/session.py:3676\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3673\u001b[0m last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3675\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 3676\u001b[0m     \u001b[43m_flush_log_streams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3678\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstance_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_wrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE:\n\u001b[1;32m   3687\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/conda_sagemaker/lib/python3.10/site-packages/sagemaker/session.py:4742\u001b[0m, in \u001b[0;36m_flush_log_streams\u001b[0;34m(stream_names, instance_count, client, log_group, job_name, positions, dot, color_wrap)\u001b[0m\n\u001b[1;32m   4738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stream_names) \u001b[38;5;241m<\u001b[39m instance_count:\n\u001b[1;32m   4739\u001b[0m     \u001b[38;5;66;03m# Log streams are created whenever a container starts writing to stdout/err, so this list\u001b[39;00m\n\u001b[1;32m   4740\u001b[0m     \u001b[38;5;66;03m# may be dynamic until we have a stream for every instance.\u001b[39;00m\n\u001b[1;32m   4741\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4742\u001b[0m         streams \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe_log_streams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4743\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogGroupName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4744\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogStreamNamePrefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4745\u001b[0m \u001b[43m            \u001b[49m\u001b[43morderBy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLogStreamName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4746\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4747\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4748\u001b[0m         stream_names \u001b[38;5;241m=\u001b[39m [s[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogStreamName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m streams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogStreams\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m   4750\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnextToken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m streams:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/conda_sagemaker/lib/python3.10/site-packages/botocore/client.py:508\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/conda_sagemaker/lib/python3.10/site-packages/botocore/client.py:915\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    913\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    914\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidSignatureException) when calling the DescribeLogStreams operation: Signature expired: 20230318T173231Z is now earlier than 20230318T174337Z (20230318T174837Z - 5 min.)"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit({'train': train_data_path, 'valid': valid_data_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3979aae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-312202024311/huggingface-pytorch-training-2023-03-18-17-09-49-922/output/model.tar.gz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "24a72227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-training'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.base_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29cd9fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobName': 'huggingface-pytorch-training-2023-03-18-17-09-49-922',\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:312202024311:training-job/huggingface-pytorch-training-2023-03-18-17-09-49-922',\n",
       " 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-us-east-1-312202024311/huggingface-pytorch-training-2023-03-18-17-09-49-922/output/model.tar.gz'},\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'SecondaryStatus': 'Completed',\n",
       " 'HyperParameters': {'epochs': '1',\n",
       "  'model_name': '\"distilbert-base-uncased\"',\n",
       "  'sagemaker_container_log_level': '20',\n",
       "  'sagemaker_job_name': '\"huggingface-pytorch-training-2023-03-18-17-09-49-922\"',\n",
       "  'sagemaker_program': '\"train_hf.py\"',\n",
       "  'sagemaker_region': '\"us-east-1\"',\n",
       "  'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-312202024311/huggingface-pytorch-training-2023-03-18-17-09-49-922/source/sourcedir.tar.gz\"',\n",
       "  'train_batch_size': '32'},\n",
       " 'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.7.1-transformers4.6.1-gpu-py36-cu110-ubuntu18.04',\n",
       "  'TrainingInputMode': 'File',\n",
       "  'EnableSageMakerMetricsTimeSeries': True},\n",
       " 'RoleArn': 'arn:aws:iam::312202024311:role/Sagemaker-FullAccess',\n",
       " 'InputDataConfig': [{'ChannelName': 'train',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/training',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'},\n",
       "  {'ChannelName': 'valid',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-us-east-1-312202024311/sagemaker-scikit-learn-2023-03-18-15-21-18-761/output/validation',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'}],\n",
       " 'OutputDataConfig': {'KmsKeyId': '',\n",
       "  'S3OutputPath': 's3://sagemaker-us-east-1-312202024311/'},\n",
       " 'ResourceConfig': {'InstanceType': 'ml.p3.2xlarge',\n",
       "  'InstanceCount': 1,\n",
       "  'VolumeSizeInGB': 30},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'CreationTime': datetime.datetime(2023, 3, 18, 17, 9, 52, 209000, tzinfo=tzlocal()),\n",
       " 'TrainingStartTime': datetime.datetime(2023, 3, 18, 17, 11, 23, 40000, tzinfo=tzlocal()),\n",
       " 'TrainingEndTime': datetime.datetime(2023, 3, 18, 17, 58, 2, 693000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 3, 18, 17, 58, 28, 702000, tzinfo=tzlocal()),\n",
       " 'SecondaryStatusTransitions': [{'Status': 'Starting',\n",
       "   'StartTime': datetime.datetime(2023, 3, 18, 17, 9, 52, 209000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2023, 3, 18, 17, 11, 23, 40000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Preparing the instances for training'},\n",
       "  {'Status': 'Downloading',\n",
       "   'StartTime': datetime.datetime(2023, 3, 18, 17, 11, 23, 40000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2023, 3, 18, 17, 11, 58, 798000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Downloading input data'},\n",
       "  {'Status': 'Training',\n",
       "   'StartTime': datetime.datetime(2023, 3, 18, 17, 11, 58, 798000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2023, 3, 18, 17, 57, 17, 235000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training image download completed. Training in progress.'},\n",
       "  {'Status': 'Uploading',\n",
       "   'StartTime': datetime.datetime(2023, 3, 18, 17, 57, 17, 235000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2023, 3, 18, 17, 58, 2, 693000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Uploading generated training model'},\n",
       "  {'Status': 'Completed',\n",
       "   'StartTime': datetime.datetime(2023, 3, 18, 17, 58, 2, 693000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2023, 3, 18, 17, 58, 2, 693000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training job completed'}],\n",
       " 'EnableNetworkIsolation': False,\n",
       " 'EnableInterContainerTrafficEncryption': False,\n",
       " 'EnableManagedSpotTraining': False,\n",
       " 'TrainingTimeInSeconds': 2799,\n",
       " 'BillableTimeInSeconds': 2799,\n",
       " 'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-312202024311/',\n",
       "  'CollectionConfigurations': []},\n",
       " 'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-312202024311/',\n",
       "  'ProfilingIntervalInMilliseconds': 500},\n",
       " 'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1679159391',\n",
       "   'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "   'VolumeSizeInGB': 0,\n",
       "   'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       " 'ProfilerRuleEvaluationStatuses': [{'RuleConfigurationName': 'ProfilerReport-1679159391',\n",
       "   'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:312202024311:processing-job/huggingface-pytorch-traini-profilerreport-1679159391-13639946',\n",
       "   'RuleEvaluationStatus': 'NoIssuesFound',\n",
       "   'LastModifiedTime': datetime.datetime(2023, 3, 18, 17, 58, 28, 696000, tzinfo=tzlocal())}],\n",
       " 'ProfilingStatus': 'Enabled',\n",
       " 'ResponseMetadata': {'RequestId': 'e2f0c47d-fcc6-4a7e-bbee-19443be1aebf',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e2f0c47d-fcc6-4a7e-bbee-19443be1aebf',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '4060',\n",
       "   'date': 'Sat, 18 Mar 2023 20:45:12 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traninghuggingface_estimator.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4819f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n",
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.7.1-transformers4.6.1-gpu-py36-cu110-ubuntu18.04\n",
      "{'InstanceType': 'ml.p3.2xlarge', 'InstanceCount': 1, 'VolumeSizeInGB': 30}\n",
      "2799\n"
     ]
    }
   ],
   "source": [
    "training_job_description = huggingface_estimator.jobs[-1].describe()\n",
    "print(training_job_description['TrainingJobStatus'])\n",
    "print(training_job_description['AlgorithmSpecification']['TrainingImage'])\n",
    "print(training_job_description['ResourceConfig'])\n",
    "print(training_job_description['TrainingTimeInSeconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04bfb8",
   "metadata": {},
   "source": [
    "# Deploy with the Hugging Face container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8f2b272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "huggingface_predictor = huggingface_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a73613cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\"inputs\": \"Brilliant phone allaround, I'm extremely happy with it.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71b3339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.9276689291000366}]\n"
     ]
    }
   ],
   "source": [
    "prediction = huggingface_predictor.predict(test_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c412f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\"inputs\": \"Dissapointed with the product, have to return it now!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bccab76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.999360203742981}]\n"
     ]
    }
   ],
   "source": [
    "prediction = huggingface_predictor.predict(test_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db7ebb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f8166",
   "metadata": {},
   "source": [
    "# Deploy with the PyTorch container (Torchserve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c21f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel \n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84f11135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, \n",
    "                         sagemaker_session=sagemaker_session, \n",
    "                         serializer=JSONSerializer(), \n",
    "                         deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc3d14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=huggingface_estimator.model_data,\n",
    "    role=role, \n",
    "    entry_point='torchserve-predictor.py',\n",
    "    source_dir='src',\n",
    "    framework_version='1.7.1',\n",
    "    py_version='py36',\n",
    "    predictor_cls=SentimentAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "106c2767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "pytorch_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "260a43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {'text': \"Brilliant phone allaround, I'm extremely happy with it.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5a088b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-inference-2023-03-18-19-20-37-442'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "501f52ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "prediction = pytorch_predictor.predict(test_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ebc11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {'text': \"Dissapointed with the product, have to return it now!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9d32111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "prediction = pytorch_predictor.predict(test_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "292eae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No monitors found for endpoint. endpoint: pytorch-inference-2023-03-18-19-20-37-442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d36a486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc58662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_sagemaker",
   "language": "python",
   "name": "conda_sagemaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
